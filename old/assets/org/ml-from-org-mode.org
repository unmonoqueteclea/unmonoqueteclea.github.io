#+TITLE:     Machine Learning from org-mode
#+AUTHOR:    Pablo González Carrizo
#+EMAIL:     pgonzalezcarrizo@gmail.com
#+OPTIONS:      toc:nil
#+PROPERTY:     header-args:restclient :var url="https://bigml.io" :var auth ="?username=YOUR_USERNAME&api_key=YOUR_API_KEY"


As a Machine Learning engineer at [[https://bigml.com/][BigML]], I use [[https://jupyter.org/][Jupyter Notebooks]] a
lot. Although there are some people doing great Python libraries fully
written in notebooks (see the [[https://www.fast.ai/2019/12/02/nbdev/][great work done by Jeremy Howard]]) I
only use them for early stage experimenting (actually, I spend many
hours experimenting with data). For me, notebooks are a great tool to
show my work, but they were not created as a way to implement and
organize software (see this [[https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI][controversial but very interesting talk at
JupyterCon]])

During the last months I have been exploring different ways of doing
things. Emacs is becoming my Operative System and I am starting to
live in a *plain text world*. I use *org mode* to take notes about
absolutely everything, [[https://github.com/bastibe/org-journal][org-journal]] to mantain my personal dialy
journal, [[https://github.com/skeeto/elfeed][elfeed]] to read RSS feeds, [[https://github.com/yuya373/emacs-slack][emacs-slack]] as Slack client, and
many more examples that I will write about in a future post.

Sadly, Jupyter Notebooks don't fit well in this new life philosophy. I
realized that people had been doing [[https://invidio.us/watch?v=bTkXg2LZIMQ&local=1&nojs=0&player_style=youtube][literate programming]] long time ago
it /became cool/, and Jupyter Notebooks are not the only way. I knew
[[https://orgmode.org/worg/org-contrib/babel/][org-babel]], that lets you execute source code within org mode
documents, but I wasn't sure if it would be a right alternative to
notebooks. And then I found these two posts ([[https://jao.io/blog/2020-02-26-literate-programming.html][literate programming]] and
[[https://justinbarclay.me/posts/literate_programming_against_rest_apis/][literate-programming-against-rest-apis]]) about literate programming in
emacs and they really opened my eyes.

In this post, we will do Machine Learning from an org file using
BigML's API. [[https://bigml.com/][BigML]] is a Machine Learning As A Service platform that
removes the complexities of Machine Learning so you can focus on what
matters most, enhancing and automating decision making. I will use its
*REST API* to create predictive models.

To make http requests from org-mode, I will use [[https://github.com/pashky/restclient.el][restclient]]  and an
extension to it that provides org-babel support, [[https://github.com/alf/ob-restclient.el][ob-restclient]].

In the header of the org file I will configure the url and credentials
to use [[https://bigml.com/api][BigML's API]] (you can access the latest full-featured version of
BigML with a [[https://bigml.com/accounts/register/][free account]]):

#+BEGIN_SRC org
#+TITLE:     Machine Learning from org-mode
#+AUTHOR:    Pablo González Carrizo
#+PROPERTY:     header-args:restclient :var url="https://bigml.io" :var auth ="?username=YOUR_USERNAME&api_key=COPY_YOUR_API_KEY_HERE"
#+END_SRC

First of all, we will define this little helper block (inspired by
[[https://justinbarclay.me/posts/literate_programming_against_rest_apis/][this blog post]]) that will clean the output, parse the BigML's API JSON
response and extract the id of the resource. All the resources
generated by *BigML's API* contain a /resource/ file with the id of the
created resource. We will use [[https://www.gnu.org/software/emacs/manual/html_node/elisp/][elisp]] to define this function, but we
could have used whatever language we want.

#+NAME: resource
#+BEGIN_SRC emacs-lisp :var path=""
  (require 'json)
  (let* ((json-string (string-trim
                       (replace-regexp-in-string
                        "^#\\+BEGIN_SRC js\\|^#\\+END_SRC\\|^//[[:print:]]+"
                        ""
                        (with-temp-buffer
                          (insert-file-contents path)
                          (buffer-string)))))
         (json-object-type 'hash-table)
         (json-array-type 'list)
         (json-key-type 'string)
         (json (json-read-from-string json-string)))
    (gethash "resource" json))
#+END_SRC


Now, let's explore the data. I will use the all-known [[iris][iris
ataset]]. For that, I will use a *bash* source block.

10 first lines of the csv file:

#+BEGIN_SRC bash
curl "https://static.bigml.com/csv/iris.csv" |  head -10
#+END_SRC

#+RESULTS:
| sepal length | sepal width | petal length | petal width | species     |
|          5.1 |         3.5 |          1.4 |         0.2 | Iris-setosa |
|          4.9 |         3.0 |          1.4 |         0.2 | Iris-setosa |
|          4.7 |         3.2 |          1.3 |         0.2 | Iris-setosa |
|          4.6 |         3.1 |          1.5 |         0.2 | Iris-setosa |
|          5.0 |         3.6 |          1.4 |         0.2 | Iris-setosa |
|          5.4 |         3.9 |          1.7 |         0.4 | Iris-setosa |
|          4.6 |         3.4 |          1.4 |         0.3 | Iris-setosa |
|          5.0 |         3.4 |          1.5 |         0.2 | Iris-setosa |
|          4.4 |         2.9 |          1.4 |         0.2 | Iris-setosa |

The response to the previous command is shown as an *org table*, so I can
use all the [[https://orgmode.org/manual/Tables.html][available commands]] for tables in org mode, and even use
[[https://orgmode.org/worg/org-tutorials/org-spreadsheet-intro.html][org mode spreadsheet]] capabilities!

With simple bash utilities, I can print the number of rows of the csv
file

#+BEGIN_SRC bash
curl "https://static.bigml.com/csv/iris.csv" |  wc -l
#+END_SRC

#+RESULTS:
: 151

Now, let's upload the data to BigML. These are the steps we should
follow:

- Upload the file as a *source* to BigML.
- Create a **dataset** from the *source* (BigML will analyze all the
  content from the original CSV file and prepare it for modelling
  tasks).
- Create a *predictive model* from our dataset.
- Upload new data to obtain *predictions* from the model.


Let's create the **source** with a simple **HTTP POST request**. The
response will be stored in a file called **source.json**



Let's create the *Source* with a simple *POST http request*. We will store
the response in a text file called /source.json/

#+NAME: source
#+BEGIN_SRC restclient :file source.json
POST :url/source/:auth
Content-Type: application/json
{"remote": "https://static.bigml.com/csv/iris.csv"}
#+END_SRC

#+RESULTS: source
[[file:source.json]]

From the *source*, we will create a *dataset*. See how easy this is

#+BEGIN_SRC restclient :var id=resource("source.json") :file dataset.json
POST :url/dataset/:auth
Content-Type: application/json
{"source": ":id"}
#+END_SRC

#+RESULTS:
[[file:dataset.json]]

Let's stop for a moment to review what we have just done.

- We explored the csv file using a *bash source block*.
- We used a *DSL* (Domain-Specific Langugage) to perform a *HTTP
  POST request* to the API.
- We used *elisp* to extract the **resource id** from the response
  of previous request.
- We used again the *DSL* to perform another *HTTP POST request*,
  using the previously extracted *resource id* as an argument.

And *everything from the same org file*!

*Emacs win*!

I will create now the *predictive model* from the previously created
*dataset*:

#+BEGIN_SRC restclient :var id=resource("dataset.json") :file ensemble.json
POST :url/ensemble/:auth
Content-Type: application/json
{"dataset": ":id"}
#+END_SRC

#+RESULTS:
[[file:ensemble.json]]


And now, let's make *predictions* and show the results in this document:

#+BEGIN_SRC restclient :var id=resource("ensemble.json")
POST :url/prediction/:auth
Content-Type: application/json
{"ensemble": ":id",
 "input_data": {"sepal length": 6 , "sepal width": 3,
                "petal length": 3}}
#+END_SRC

#+RESULTS:
#+BEGIN_SRC js
{
  "boosted_ensemble": false,
  "category": 0,
  "code": 201,
  "combiner": null,
  "confidence": 0.59016,
  "confidence_bounds": null,
  "confidences": [
    [
      "Iris-versicolor",
      0.59016
    ],
    [
      "Iris-virginica",
      0.23788
    ],
    [
      "Iris-setosa",
      0
    ]
  ],
  "configuration": null,
  "configuration_status": false,
  "created": "2020-03-15T13:20:44.490111",
  "credits": 0.01,
  "dataset": "dataset/5e6d2db77811dd14a30011ef",
  "dataset_status": true,
  "description": "",
  "ensemble": "ensemble/5e6d2dc45299630d1c0013e9",
  "error_predictions": 0,
  "explanation": null,
  "fields": {
    "000000": {
      "column_number": 0,
      "datatype": "double",
      "name": "sepal length",
      "optype": "numeric",
      "order": 0,
      "preferred": true
    },
    "000001": {
      "column_number": 1,
      "datatype": "double",
      "name": "sepal width",
      "optype": "numeric",
      "order": 1,
      "preferred": true
    },
    "000002": {
      "column_number": 2,
      "datatype": "double",
      "name": "petal length",
      "optype": "numeric",
      "order": 2,
      "preferred": true
    },
    "000003": {
      "column_number": 3,
      "datatype": "double",
      "name": "petal width",
      "optype": "numeric",
      "order": 3,
      "preferred": true
    },
    "000004": {
      "column_number": 4,
      "datatype": "string",
      "name": "species",
      "optype": "categorical",
      "order": 4,
      "preferred": true,
      "term_analysis": {
        "enabled": true
      }
    }
  },
  "finished_predictions": 10,
  "importance": {
    "000002": 1
  },
  "input_data": {
    "petal length": 3,
    "sepal length": 6,
    "sepal width": 3
  },
  "locale": "en_US",
  "missing_strategy": 0,
  "model": "",
  "model_status": true,
  "model_type": 1,
  "models": [
    "model/5e6d2dc7440ca11807004017",
    "model/5e6d2dc7440ca11807004019",
    "model/5e6d2dc8440ca1180700401b",
    "model/5e6d2dc8440ca1180700401d",
    "model/5e6d2dc8440ca1180700401f",
    "model/5e6d2dc8440ca11807004021",
    "model/5e6d2dc8440ca11807004023",
    "model/5e6d2dc8440ca11807004025",
    "model/5e6d2dc8440ca11807004027",
    "model/5e6d2dc8440ca11807004029"
  ],
  "name": "iris",
  "name_options": "operating kind=probability, 3 inputs",
  "number_of_models": 10,
  "objective_field": "000004",
  "objective_field_name": "species",
  "objective_field_type": "categorical",
  "objective_fields": [
    "000004"
  ],
  "operating_kind": "probability",
  "output": "Iris-versicolor",
  "prediction": {
    "000004": "Iris-versicolor"

  },
  "predictions": [
    {
      "confidence": 0.86176,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.86176
        ],
        [
          "Iris-virginica",
          0.00479
        ]
      ],
      "count": 37,
      "distribution": [
        [
          "Iris-versicolor",
          36
        ],
        [
          "Iris-virginica",
          1
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 9,
      "order": 0,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00982
        ],
        [
          "Iris-versicolor",
          0.95421
        ],
        [
          "Iris-virginica",
          0.03596
        ]
      ],
      "probability": 0.95421,
      "total_count": 150
    },
    {
      "confidence": 0.42733,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.42733
        ],
        [
          "Iris-virginica",
          0.37774
        ]
      ],
      "count": 97,
      "distribution": [
        [
          "Iris-versicolor",
          51
        ],
        [
          "Iris-virginica",
          46
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 1,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00361
        ],
        [
          "Iris-versicolor",
          0.52388
        ],
        [
          "Iris-virginica",
          0.47252
        ]
      ],
      "probability": 0.52388,
      "total_count": 150
    },
    {
      "confidence": 0.41348,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.39422
        ],
        [
          "Iris-virginica",
          0.41348
        ]
      ],
      "count": 100,
      "distribution": [
        [
          "Iris-virginica",
          51
        ],
        [
          "Iris-versicolor",
          49
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 2,
      "prediction": "Iris-virginica",
      "probabilities": [
        [
          "Iris-setosa",
          0.0033
        ],
        [
          "Iris-versicolor",
          0.48838
        ],
        [
          "Iris-virginica",
          0.50832
        ]
      ],
      "probability": 0.50832,
      "total_count": 150
    },
    {
      "confidence": 0.87941,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.87941
        ],
        [
          "Iris-virginica",
          0.00412
        ]
      ],
      "count": 43,
      "distribution": [
        [
          "Iris-versicolor",
          42
        ],
        [
          "Iris-virginica",
          1
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 15,
      "order": 3,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00727
        ],
        [
          "Iris-versicolor",
          0.96182
        ],
        [
          "Iris-virginica",
          0.03091
        ]
      ],
      "probability": 0.96182,
      "total_count": 150
    },
    {
      "confidence": 0.46808,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.46808
        ],
        [
          "Iris-virginica",
          0.33656
        ]
      ],
      "count": 95,
      "distribution": [
        [
          "Iris-versicolor",
          54
        ],
        [
          "Iris-virginica",
          41
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 4,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00382
        ],
        [
          "Iris-versicolor",
          0.56625
        ],
        [
          "Iris-virginica",
          0.42993
        ]
      ],
      "probability": 0.56625,
      "total_count": 150
    },
    {
      "confidence": 0.49945,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.49945
        ],
        [
          "Iris-virginica",
          0.30723
        ]
      ],
      "count": 95,
      "distribution": [
        [
          "Iris-versicolor",
          57
        ],
        [
          "Iris-virginica",
          38
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 5,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00382
        ],
        [
          "Iris-versicolor",
          0.59771
        ],
        [
          "Iris-virginica",
          0.39847
        ]
      ],
      "probability": 0.59771,
      "total_count": 150
    },
    {
      "confidence": 0.76619,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.76619
        ],
        [
          "Iris-virginica",
          0.05505
        ]
      ],
      "count": 51,
      "distribution": [
        [
          "Iris-versicolor",
          45
        ],
        [
          "Iris-virginica",
          6
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 3,
      "order": 6,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00487
        ],
        [
          "Iris-versicolor",
          0.87115
        ],
        [
          "Iris-virginica",
          0.12397
        ]
      ],
      "probability": 0.87115,
      "total_count": 150
    },
    {
      "confidence": 0.41117,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.39073
        ],
        [
          "Iris-virginica",
          0.41117
        ]
      ],
      "count": 94,
      "distribution": [
        [
          "Iris-virginica",
          48
        ],
        [
          "Iris-versicolor",
          46
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 7,
      "prediction": "Iris-virginica",
      "probabilities": [
        [
          "Iris-setosa",
          0.00393
        ],
        [
          "Iris-versicolor",
          0.48744
        ],
        [
          "Iris-virginica",
          0.50863
        ]
      ],
      "probability": 0.50863,
      "total_count": 150
    },
    {
      "confidence": 0.86024,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.86024
        ],
        [
          "Iris-virginica",
          0.0115
        ]
      ],
      "count": 48,
      "distribution": [
        [
          "Iris-versicolor",
          46
        ],
        [
          "Iris-virginica",
          2
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 7,
      "order": 8,
      "prediction": "Iris-versicolor",
      "probabilities": [
        [
          "Iris-setosa",
          0.00667
        ],
        [
          "Iris-versicolor",
          0.94544
        ],
        [
          "Iris-virginica",
          0.04789
        ]
      ],
      "probability": 0.94544,
      "total_count": 150
    },
    {
      "confidence": 0.45719,
      "confidences": [
        [
          "Iris-setosa",
          0
        ],
        [
          "Iris-versicolor",
          0.35423
        ],
        [
          "Iris-virginica",
          0.45719
        ]
      ],
      "count": 103,
      "distribution": [
        [
          "Iris-virginica",
          57
        ],
        [
          "Iris-versicolor",
          46
        ]
      ],
      "importance": {
        "000002": 1
      },
      "node_id": 1,
      "order": 9,
      "prediction": "Iris-virginica",
      "probabilities": [
        [
          "Iris-setosa",
          0.00301
        ],
        [
          "Iris-versicolor",
          0.44526
        ],
        [
          "Iris-virginica",
          0.55173
        ]
      ],
      "probability": 0.55173,
      "total_count": 150
    }
  ],
  "private": true,
  "probabilities": [
    [
      "Iris-setosa",
      0.00501
    ],
    [
      "Iris-versicolor",
      0.68415
    ],
    [
      "Iris-virginica",
      0.31083
    ]
  ],
  "probability": 0.68415,
  "project": null,
  "query_string": "",
  "resource": "prediction/5e6e2bac66a97429d60099b8",
  "shared": false,
  "source": "source/5e6d2d935299630d1c0013e6",
  "source_status": true,
  "status": {
    "code": 5,
    "elapsed": 177.0,
    "message": "The prediction has been created",
    "progress": 1.0
  },
  "subscription": true,
  "tags": [],
  "task": "classification",
  "type": 0,
  "updated": "2020-03-15T13:20:44.490133",
  "vote_count": 0.7,
  "vote_counts": [
    [
      "Iris-versicolor",
      0.7
    ],
    [
      "Iris-virginica",
      0.3
    ],
    [
      "Iris-setosa",
      0
    ]
  ]
}
// POST https://bigml.io/prediction/
// HTTP/1.1 201 CREATED
// Access-Control-Allow-Methods: POST,GET,PUT,DELETE
// Access-Control-Allow-Origin: *
// Cache-Control: max-age=0, no-cache, no-store, must-revalidate
// Content-Type: application/json
// Date: Sun, 15 Mar 2020 13:20:44 GMT
// Location: http://bigml.io/andromeda/prediction/5e6e2bac66a97429d60099b8
// Server: nginx
// X-Content-Type-Options: nosniff
// X-Frame-Options: SAMEORIGIN
// X-UA-Compatible: IE=Edge
// X-XSS-Protection: 1; mode=block
// transfer-encoding: chunked
// Connection: keep-alive
// Request duration: 0.491885s
#+END_SRC
