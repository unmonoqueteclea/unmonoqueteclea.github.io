<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title><![CDATA[@unmonoqueteclea - projects]]></title>
<description><![CDATA[@unmonoqueteclea - projects]]></description>
<link>https://unmonoqueteclea.github.io/tag-projects.html</link>
<lastBuildDate>Mon, 15 Sep 2025 20:11:34 +0200</lastBuildDate>
<item>
  <title><![CDATA[Re: Status of Voilib and building AI tools]]></title>
  <description><![CDATA[
<p>
Last week, a <a href="https://github.com/unmonoqueteclea/voilib">Voilib</a> user reached out to me with two questions: how the project is
currently progressing, and whether I could recommend other AI-based tools that might
support his learning journey.
</p>

<p>
I‚Äôd like to share part of my reply here, since I believe it could be useful for others as
well:
</p>

<blockquote>
<p>
I‚Äôm glad to hear Voilib was useful for you. I have to admit that keeping it updated isn‚Äôt
one of my main priorities these days. It‚Äôs a project that‚Äôs a bit too big to simply
self-host on a Raspberry Pi and check in on every few weeks. It‚Äôs harder to maintain when
the number of channels grows: the transcription process uses a lot of CPU, and the
embeddings database grows really quickly.  Still, building it end-to-end was a lot of fun
and a huge learning experience.
</p>

<p>
If I had to rebuild it today, I would try to simplify every component much more. For
example, using <code>sqlite-vec</code> could be a nice way to store embeddings without relying on an
additional service. And without any doubt, I‚Äôd make heavy use of <a href="https://simonwillison.net/">Simon Willison</a>‚Äôs
excellent llm library (<a href="https://github.com/simonw/llm">https://github.com/simonw/llm</a>) as it handles embeddings, tool
calls, and supports any LLM provider. Both in a <code>CLI</code> and as a <code>Python</code> library.
</p>

<p>
In fact, that‚Äôs what I recommend to everyone: explore everything Simon has built on top of
that library. It‚Äôs impressive, and you can learn how agents really work without all the
unnecessary complexity others often add.  Write a <code>for</code> loop using tool calls and that
library and you will have built your own agent.
</p>

<p>
Good luck on your learning journey!
</p>

<p>
Best,
Pablo
</p>
</blockquote>


<p>
And that's it. AI hype or AI winter, just start small (really small),
build things, and you‚Äôll see what‚Äôs signal and what‚Äôs just noise.
</p>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> <a href="https://unmonoqueteclea.github.io/tag-llm.html">llm</a> <a href="https://unmonoqueteclea.github.io/tag-ml.html">ml</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <category><![CDATA[llm]]></category>
  <category><![CDATA[ml]]></category>
  <link>https://unmonoqueteclea.github.io/2025-09-15-re:-status-of-voilib-and-building-ai-tools.html</link>
  <guid>https://unmonoqueteclea.github.io/2025-09-15-re:-status-of-voilib-and-building-ai-tools.html</guid>
  <pubDate>Mon, 15 Sep 2025 19:45:00 +0200</pubDate>
</item>
<item>
  <title><![CDATA[Introducing jira.el: Emacs integration for Jira]]></title>
  <description><![CDATA[
<p>
I've just publised my first <code>Emacs</code> package: <a href="https://github.com/unmonoqueteclea/jira.el">jira.el</a>: an Emacs
integration for <code>Jira</code>.
</p>


<figure id="org2f1851b">
<a href="https://stable.melpa.org/#/jira"><img src="https://stable.melpa.org/packages/jira-badge.svg" alt="jira-badge.svg" class="org-svg"></a>

</figure>

<blockquote>
<p>
If you have no choice but to use Jira, at least do it without leaving Emacs.
</p>
</blockquote>

<p>
<a href="https://github.com/unmonoqueteclea/jira.el">jira.el</a> is an <code>Emacs</code> package that brings the "power" of Atlassian's
<code>Jira</code> right into your editor. It lets you list, filter, and inspect
issues, modify properties, and even add worklogs‚Äîall without leaving
Emacs.
</p>

<pre class="example" id="org0d7d043">
‚ÑπÔ∏è Status &lt;2025-03-17 Mon&gt;: Jira is already part of MELPA! üéâ
</pre>

<p>
Key Features:
</p>

<ul class="org-ul">
<li><b>List &amp; Filter Issues</b>: Quickly view the issues assigned to you (or
your team) and apply custom JQL filters.</li>
<li><b>Issue Details</b>: Open and inspect detailed information about any Jira
issue.</li>
<li><b>Modify Issues</b>: Update properties and add worklogs directly from
your Emacs session.</li>
<li><b>Tempo Integration</b>: Seamlessly display <a href="https://www.tempo.io/">Tempo</a> worklogs to keep track
of time spent on tasks.</li>
</ul>



<figure id="org4a8274d">
<img src="https://unmonoqueteclea.github.io/static/jirael-list-issues.png" alt="jirael-list-issues.png" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>List issues in jira.el</figcaption>
</figure>


<figure id="org2f3147e">
<img src="https://unmonoqueteclea.github.io/static/jirael-list-worklogs.png" alt="jirael-list-worklogs.png" width="100%">

<figcaption><span class="figure-number">Figure 2: </span>List worklogs in jira.el</figcaption>
</figure>


<p>
<a href="https://github.com/unmonoqueteclea/jira.el">jira.el</a> combines a <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Tabulated-List-Mode.html">Tabulated List Mode</a>-based UI, with <a href="https://magit.vc/">Magit</a>-like
keyboard-driven menus, a combination loved by <code>Emacs</code> users.
</p>

<p>
Check out the <a href="https://github.com/unmonoqueteclea/jira.el">jira.el</a> documentation on <a href="https://github.com/unmonoqueteclea/jira.el">Github</a> for further details and
usage tips!
</p>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> <a href="https://unmonoqueteclea.github.io/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://unmonoqueteclea.github.io/2025-02-28-introducing-jira.el:-emacs-integration-for-jira.html</link>
  <guid>https://unmonoqueteclea.github.io/2025-02-28-introducing-jira.el:-emacs-integration-for-jira.html</guid>
  <pubDate>Fri, 28 Feb 2025 19:20:00 +0100</pubDate>
</item>
<item>
  <title><![CDATA[Voilib: Time to say goodbye]]></title>
  <description><![CDATA[
<p>
Voilib permanently shut down on December 14th, 2024.
</p>


<figure id="org20ee678">
<img src="https://unmonoqueteclea.github.io/static/voilib-end.jpeg" alt="voilib-end.jpeg" width="80%">

<figcaption><span class="figure-number">Figure 1: </span>End of Voilib</figcaption>
</figure>

<p>
The decision wasn‚Äôt easy, but maintaining a project like this without
funding is challenging. While models like Whisper have revolutionized
transcription, processing countless hours of audio remains a complex
task. Additionally, managing large collections of embeddings requires
fine-tuning the retrieval system‚Äîsomething I currently don‚Äôt have the
time to tackle.
</p>

<p>
That said, <a href="https://github.com/unmonoqueteclea/voilib">Voilib is Open Source</a>, so anyone can set up their own
instance with ease. I plan to release updates soon to simplify
installation and enhance its robustness. And, of course, the project
is open for external contributions.
</p>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2024-12-22-voilib:-time-to-say-goodbye.html</link>
  <guid>https://unmonoqueteclea.github.io/2024-12-22-voilib:-time-to-say-goodbye.html</guid>
  <pubDate>Sun, 22 Dec 2024 13:31:00 +0100</pubDate>
</item>
<item>
  <title><![CDATA[Introducing valencia-now: real-time traffic information about Valencia]]></title>
  <description><![CDATA[
<p>
<a href="https://valencianow.unmonoqueteclea.freemyip.com/">valencia-now</a>, a project that I announced a few days ago with great
reception on <a href="https://twitter.com/unmonoqueteclea/status/1769407185505644638">X</a>, is now public as of today üéâ.
</p>

<p>
This simple dashboard allows visualization of <b>real-time</b>, <b>historical</b>,
and <b>aggregated</b> data on <b>traffic</b> and <b>air quality</b> in Valencia.
</p>



<figure id="org87263f4">
<img src="https://unmonoqueteclea.github.io/static/valencianow.gif" alt="valencianow.gif" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>valencia-now: real-time traffic information</figcaption>
</figure>
<div id="outline-container-orge03b76c" class="outline-2">
<h2 id="orge03b76c">Real-time information</h2>
<div class="outline-text-2" id="text-orge03b76c">
<p>
The <a href="https://valencia.opendatasoft.com">open data portal</a> of the Spanish city of Valencia provides
<b>real-time traffic data</b> for both <a href="https://valencia.opendatasoft.com/explore/dataset/punts-mesura-trafic-espires-electromagnetiques-puntos-medida-trafico-espiras-ele/">cars (and other motor vehicles)</a> and
<a href="https://valencia.opendatasoft.com/explore/dataset/punts-mesura-bicis-espires-electromagnetiques-puntos-medida-bicis-espiras-electr/table/">bicycles</a>. A series of electromagnetic loops distributed throughout the
city are capable of measuring the <b>intensity of vehicles</b> passing through
them. This information is published on an <code>hourly basis</code> for motor
vehicles and approximately every <code>30 minutes</code> for bicycles. With that
information, <a href="https://valencianow.unmonoqueteclea.freemyip.com/">valencia-now</a> is able to build these two maps representing
current traffic intensity:
</p>


<figure id="org378daa7">
<img src="https://unmonoqueteclea.github.io/static/valencianow-map.webp" alt="valencianow-map.webp" width="100%">

<figcaption><span class="figure-number">Figure 2: </span>Traffic maps in valencia-now</figcaption>
</figure>


<p>
The <b>bicycle traffic</b> is also represented in the same way, as well as
the <b>air quality</b> data obtained from various measurement stations
located in different parts of the city. In this case, we are
representing the air quality index, a value that can range from <code>1</code>
(<code>hazardous</code>) in color <b>purple</b> to <code>6</code> (<code>good</code>) in color <b>blue</b>.
</p>




<figure id="orgb614eee">
<img src="https://unmonoqueteclea.github.io/static/valencianow-ica.webp" alt="valencianow-ica.webp" width="100%">

<figcaption><span class="figure-number">Figure 3: </span>Air quality map in valencia-now</figcaption>
</figure>
</div>
</div>
<div id="outline-container-orgb43ca62" class="outline-2">
<h2 id="orgb43ca62">Historical and aggregated data</h2>
<div class="outline-text-2" id="text-orgb43ca62">
<p>
If I were to stop at that point, I wouldn't be adding much additional
value to this data, since the open data portal itself already provides
some simple visualizations of the current state of traffic and air
quality.
</p>

<p>
However, <a href="https://valencianow.unmonoqueteclea.freemyip.com/">valencia-now</a> is also <b>collecting and storing this information</b>
which allows me not only to see the current status but also the
<b>evolution</b>.
</p>


<figure id="org83bf206">
<img src="https://unmonoqueteclea.github.io/static/valencianow-historical.webp" alt="valencianow-historical.webp" width="100%">

<figcaption><span class="figure-number">Figure 4: </span>Traffic data from a sensor on a bridge crossing the City Of Arts</figcaption>
</figure>

<p>
With that historical data, I am also able to provide aggregations such
as the following one that shows how the <b>air quality in the city centre
improved just a day after the <a href="https://en.wikipedia.org/wiki/Valencia_Fallas">Fallas</a> finished</b>.
</p>


<figure id="org0fa87ef">
<img src="https://unmonoqueteclea.github.io/static/valencianow-agg.webp" alt="valencianow-agg.webp" width="100%">

<figcaption><span class="figure-number">Figure 5: </span>Air quality data by day from a sesnor located in the city centre</figcaption>
</figure>
</div>
</div>
<div id="outline-container-org40f45e6" class="outline-2">
<h2 id="org40f45e6">Next steps</h2>
<div class="outline-text-2" id="text-org40f45e6">
<p>
In the following days, I would like to create some additional
blogposts.  I want to explain technical details about the <b>data
ingestion</b> and the <b>data transformation</b> processes (<code>spoiler</code>, <a href="https://www.tinybird.co/">tinybird</a>
made this extremly simple) and also about <b>public open data
iniciatives</b>.
</p>

<p>
At some point in time I would like to make the collected data
available for everyone, but this will require some work.
</p>

<p>
üó®Ô∏è As always, feel free to contact me (<code>unmonoqueteclea@gmail.com</code>) for
whatever doubt, suggestion or idea you may have. Happy to receive your
feedback!
</p>
</div>
</div>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2024-03-21-introducing-valencia-now:-real-time-traffic-information-about-valencia.html</link>
  <guid>https://unmonoqueteclea.github.io/2024-03-21-introducing-valencia-now:-real-time-traffic-information-about-valencia.html</guid>
  <pubDate>Fri, 22 Mar 2024 09:00:00 +0100</pubDate>
</item>
<item>
  <title><![CDATA[The technology behind Voilib]]></title>
  <description><![CDATA[
<p>
Each week, <a href="https://github.com/unmonoqueteclea/voilib">Voilib</a> diligently <b>collects and transcribes</b> hundreds of
podcast episodes. These valuable transcripts undergo a meticulous
indexing process, enabling a sophisticated <b>semantic search</b>
capability. As a result, our users can effortlessly execute
intelligent queries, pinpointing precisely the most relevant fragments
of podcast episodes.
</p>

<p>
I launched <b>Voilib</b> in December 2022 and, some months later, I decided
to embrace openness by making Voilib <a href="https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html">Open Source</a>. This alowed everyone
to create their own instances, transcribe, and index their cherished
podcasts. You'll find it easily accessible on both <a href="https://github.com/unmonoqueteclea/voilib">Github</a> and
<a href="https://gitlab.com/unmonoqueteclea/voilib">Gitlab</a>. As promised, let me take you on a fascinating journey into the
captivating technology behind it.
</p>



<figure id="orgc1f25bc">
<img src="https://unmonoqueteclea.github.io/static/voilib.gif" alt="voilib.gif" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>Searching content in voilib.com</figcaption>
</figure>


<p>
Essentially, <a href="https://github.com/unmonoqueteclea/voilib">Voilib</a>'s work can be divided into four main tasks:
<b>collecting</b> new episodes, <b>transcribing</b> them, <b>indexing</b> all the content,
and <b>querying</b> the vector database to find relevant fragments.
</p>
<div id="outline-container-orgca24fff" class="outline-2">
<h2 id="orgca24fff">üåê  Collect (new episodes)</h2>
<div class="outline-text-2" id="text-orgca24fff">
<p>
Almost all public podcasts have an associated <code>RSS feed</code> that contains
metadata about every episode, including a link to the audio file. As
an example, <a href="http://feeds.feedburner.com/TEDTalks_audio">this</a> is the feed from the <a href="https://www.ted.com/about/programs-initiatives/ted-talks/ted-talks-daily">Ted Talks Daily</a> podcast.
</p>

<p>
<b>Voilib</b> collects and stores <b>metadata</b> from the list of podcasts feeds
manually configured by the application admin. For each episode, it
stores in a <code>SQLite</code> database things such as the title, the description,
the language or the duration.
</p>

<p>
When I want to check if new episodes were published, I just need to
run this in a command line (although I have a <b>cron job</b> configured to
run it twice a day):
</p>

<div class="org-src-container">
<pre class="src src-bash"><code>voilib-episodes --update
</code></pre>
</div>

<p>
If you want to dig into the code, check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/feed.py">feed.py</a> and <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/crawler.py">crawler.py</a>
modules.
</p>
</div>
</div>
<div id="outline-container-org3e549f1" class="outline-2">
<h2 id="org3e549f1">üó®Ô∏è Transcript (episodes audios)</h2>
<div class="outline-text-2" id="text-org3e549f1">
<p>
The podcast episodes are transcribed using <a href="https://openai.com/research/whisper">Whisper, an Open Source
Speech Recognition Model developed by OpenAI</a>. <b>Voilib</b> effectively
leverages <code>Whisper</code>, utilizing the <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> library. This
particular implementation of <code>Whisper</code> boasts exceptional efficiency,
showcasing speeds up to 70 times faster than comparable alternatives.
</p>

<p>
However, most <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> optimizations are predominantly GPU-focused
(that <b>Voilib</b> is not using yet), I must admit that I have not observed
significant improvements in CPU performance when compared to the
<a href="https://github.com/openai/whisper">official implementation</a>. Nevertheless, the accuracy of this model is
nothing short of remarkable, even for the small version with "just"
39M parameters. It is truly astonishing to think that a few years ago,
having an Open Source Speech Recognition model as swift and accurate
as this one would have been deemed nearly implausible.
</p>

<p>
When I want to transcribe the new episodes from the last 3 days, I
just need to run this (I also have a <b>cron job</b> configured to run it):
</p>

<div class="org-src-container">
<pre class="src src-bash"><code>voilib-episodes --transcribe-days 3
</code></pre>
</div>

<p>
For curious minds, you can check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/transcription.py">transcription.py</a> module.
</p>
</div>
</div>
<div id="outline-container-orgb0c809c" class="outline-2">
<h2 id="orgb0c809c">üìá Index (episodes trancriptions)</h2>
<div class="outline-text-2" id="text-orgb0c809c">
<p>
The process of generating episode transcripts involves breaking them
down into fragments, each comprising approximately 40 words. <b>Voilib</b>
employs the <a href="https://www.sbert.net/">sentence-transformers</a> <code>Python</code> library to calculate the
<b>embedding of each 40-words fragment</b>, effectively transforming it into
a <b>384-dimensional vector of floating point numbers</b>.
</p>

<p>
To shed light on the concept of <b>embeddings</b>, they can be defined as
lower-dimensional spaces that allow for the translation of
high-dimensional vectors.  The goal of embeddings is to capture
semantic similarity, ensuring that inputs with similar meanings are
placed closer together in the embedding space.
</p>

<p>
The <a href="https://www.sbert.net/">sentence-transformers</a> library stands out as the optimal choice for
creating text embeddings. This is the description from their <a href="https://www.sbert.net/">website</a>:
</p>

<blockquote>
<p>
You can use this framework to compute sentence / text embeddings for
more than 100 languages. These embeddings can then be compared
e.g. with cosine-similarity to find sentences with a similar
meaning. This can be useful for semantic textual similar, semantic
search, or paraphrase mining.
</p>

<p>
The framework is based on PyTorch and Transformers and offers a large
collection of pre-trained models tuned for various tasks. Further, it
is easy to fine-tune your own models.
</p>
</blockquote>

<p>
The model <b>Voilib</b> is using to calculate the embeddings is
<code>multi-qa-MiniLM-L6-cos-v1</code>. This model have been specifically trained
for Semantic Search with <a href="https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-dot-v1#training">215M question-answer pairs</a> from various
sources and domains.
</p>

<p>
You can find the code for Voilib's embedding calculation in the
<a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/embedding.py">embedding.py</a> module.
</p>

<p>
Those calculated vectors are then stored in a <b>vector database</b>, one of
the main components of the system. More on this in the next section.
</p>
</div>
</div>
<div id="outline-container-org34cccf3" class="outline-2">
<h2 id="org34cccf3">üîç Query (embeddings)</h2>
<div class="outline-text-2" id="text-org34cccf3">
<p>
Each episode's embeddings are meticulously preserved within a <b>vector
database</b>. In recent months, we have witnessed a surge in new
technologies specifically designed for storing embeddings. These
innovative solutions empower us to efficiently store embeddings and
seamlessly query them using cutting-edge <b>Approximate Nearest Neighbor
search</b> algorithms.
</p>

<p>
During the initial stages, <b>Voilib</b> relied on <a href="https://github.com/facebookresearch/faiss">Meta's FAISS</a> library for
embedding storage. However, to enhance the system and include
additional metadata for each embedding (that can be also used to
filter queries), I decided to migrate to <a href="https://qdrant.tech/">qdrant</a>, a higher-level
solution. With <a href="https://qdrant.tech/">qdrant</a>, we achieve the ability to incorporate
supplementary metadata while seamlessly managing embeddings. As part
of this evolution, <b>Voilib</b> now operates its own instance of the <a href="https://hub.docker.com/r/qdrant/qdrant/">qdrant
server</a>, further ensuring data autonomy and control.
</p>

<p>
For every <b>user prompt</b>, Voilib performs a swift calculation of the
corresponding embedding and efficiently queries the vector
database. This process enables the system to swiftly identify and
return the most relevant results, ensuring a seamless and satisfying
user experience.
</p>

<p>
Of course, there is another command to calculate and store embeddings
from all pending episodes:
</p>

<div class="org-src-container">
<pre class="src src-bash"><code>voilib-episodes --store
</code></pre>
</div>

<p>
More, in the <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/vector.py">vector.py</a> module.
</p>
</div>
</div>
<div id="outline-container-org52cd360" class="outline-2">
<h2 id="org52cd360">Happy to receive your feedback</h2>
<div class="outline-text-2" id="text-org52cd360">
<p>
Please feel free to reach out to me at <code>unmonoqueteclea@gmail.com</code> with
your thoughts, suggestions, or any inquiries.
</p>

<p>
I am eager to know which podcasts you would like to see available on
<a href="https://github.com/unmonoqueteclea/voilib">Voilib</a>. Additionally, if there are any specific features that you
believe would enhance your user experience and make your life easier,
please do not hesitate to share them with me. It's a fantastic
opportunity to contribute to the open-source community.
</p>

<p>
If you have been considering hosting your own instance, I would be
thrilled to support and guide you through the process.
</p>

<p>
I look forward to hearing from you!
</p>
</div>
</div>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html</link>
  <guid>https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html</guid>
  <pubDate>Thu, 03 Aug 2023 20:26:00 +0200</pubDate>
</item>
<item>
  <title><![CDATA[Voilib is now Open Source]]></title>
  <description><![CDATA[
<p>
Today, I decided to <b>open-source</b> <a href="https://github.com/unmonoqueteclea/voilib">Voilib</a> üéâ, the podcast search engine I
launched in December 2022. You can now <b>run your own instance</b> of it and
transcribe and index your favorite podcasts (or even your own
content!).You can find it on <a href="https://github.com/unmonoqueteclea/voilib">Github</a> or <a href="https://gitlab.com/unmonoqueteclea/voilib">Gitlab</a>.
</p>

<p>
Appearing in <a href="https://news.ycombinator.com/item?id=34115618">Show
HN</a> was a big boost for the project. That post was the main source of
traffic during the first days of life of <a href="https://github.com/unmonoqueteclea/voilib">Voilib</a>. I am thrilled to see
that many of those initial users still use it today to discover
relevant podcast episodes on topics they are interested in. Throughout
these months, I have received valuable feedback and kind words from
some of them.
</p>


<figure id="org99c53fc">
<img src="https://unmonoqueteclea.github.io/static/feedback-voilib.png" alt="feedback-voilib.png" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>Feedback from a Voilib user</figcaption>
</figure>

<p>
Since I am not offering <code>Voilib PRO</code> any more (I may talk about this in
the future) the only funding for this project, to at least cover
server expenses, will come from <a href="https://ko-fi.com/unmonoqueteclea">donations</a> and <a href="https://ko-fi.com/unmonoqueteclea/commissions">customized assistance</a> to
people maintaining their own instances.
</p>

<p>
In the following weeks (well&hellip; maybe months), I will publish some
blog posts explaining how the system works. I consider this is the
kind of content I would have loved to find some months ago when many
people suddenly became <code>prompt engineers</code>, but not so many people really
understood how to build actual LLM-based products beyond the chat
interface.
</p>

<p>
<b>UPDATE</b> <span class="timestamp-wrapper"><time class="timestamp" datetime="2023-08-04">[2023-08-04 Fri]</time></span> Read <a href="https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html">here</a> about the technology behind <b>Voilib</b>.
</p>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html</link>
  <guid>https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html</guid>
  <pubDate>Sun, 02 Jul 2023 12:32:00 +0200</pubDate>
</item>
</channel>
</rss>
