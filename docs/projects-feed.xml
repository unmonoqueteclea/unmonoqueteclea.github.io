<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title><![CDATA[@unmonoqueteclea - projects]]></title>
<description><![CDATA[@unmonoqueteclea - projects]]></description>
<link>https://unmonoqueteclea.github.io/tag-projects.html</link>
<lastBuildDate>Tue, 19 Mar 2024 18:40:36 +0100</lastBuildDate>
<item>
  <title><![CDATA[the technology behind Voilib]]></title>
  <description><![CDATA[
<p>
Each week, <a href="https://voilib.com">Voilib</a> diligently <b>collects and transcribes</b> hundreds of
podcast episodes. These valuable transcripts undergo a meticulous
indexing process, enabling a sophisticated <b>semantic search</b>
capability. As a result, our users can effortlessly execute
intelligent queries, pinpointing precisely the most relevant fragments
of podcast episodes.
</p>

<p>
I launched <b>Voilib</b> in December 2022 and, some months later, I decided
to embrace openness by making Voilib <a href="https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html">Open Source</a>. This alowed everyone
to create their own instances, transcribe, and index their cherished
podcasts. You'll find it easily accessible on both <a href="https://github.com/unmonoqueteclea/voilib">Github</a> and
<a href="https://gitlab.com/unmonoqueteclea/voilib">Gitlab</a>. As promised, let me take you on a fascinating journey into the
captivating technology behind it.
</p>



<figure id="org23932f3">
<img src="https://unmonoqueteclea.github.io/static/voilib.gif" alt="voilib.gif" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>Searching content in voilib.com</figcaption>
</figure>


<p>
Essentially, <a href="https://voilib.com">Voilib</a>'s work can be divided into four main tasks:
<b>collecting</b> new episodes, <b>transcribing</b> them, <b>indexing</b> all the content,
and <b>querying</b> the vector database to find relevant fragments.
</p>
<div id="outline-container-orgb000896" class="outline-2">
<h2 id="orgb000896">üåê  collect (new episodes)</h2>
<div class="outline-text-2" id="text-orgb000896">
<p>
Almost all public podcasts have an associated <code>RSS feed</code> that contains
metadata about every episode, including a link to the audio file. As
an example, <a href="http://feeds.feedburner.com/TEDTalks_audio">this</a> is the feed from the <a href="https://www.ted.com/about/programs-initiatives/ted-talks/ted-talks-daily">Ted Talks Daily</a> podcast.
</p>

<p>
<b>Voilib</b> collects and stores <b>metadata</b> from the list of podcasts feeds
manually configured by the application admin. For each episode, it
stores in a <code>SQLite</code> database things such as the title, the description,
the language or the duration.
</p>

<p>
When I want to check if new episodes were published, I just need to
run this in a command line (although I have a <b>cron job</b> configured to
run it twice a day):
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --update
</pre>
</div>

<p>
If you want to dig into the code, check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/feed.py">feed.py</a> and <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/crawler.py">crawler.py</a>
modules.
</p>
</div>
</div>
<div id="outline-container-org6242e54" class="outline-2">
<h2 id="org6242e54">üó®Ô∏è transcript (episodes audios)</h2>
<div class="outline-text-2" id="text-org6242e54">
<p>
The podcast episodes are transcribed using <a href="https://openai.com/research/whisper">Whisper, an Open Source
Speech Recognition Model developed by OpenAI</a>. <b>Voilib</b> effectively
leverages <code>Whisper</code>, utilizing the <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> library. This
particular implementation of <code>Whisper</code> boasts exceptional efficiency,
showcasing speeds up to 70 times faster than comparable alternatives.
</p>

<p>
However, most <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> optimizations are predominantly GPU-focused
(that <b>Voilib</b> is not using yet), I must admit that I have not observed
significant improvements in CPU performance when compared to the
<a href="https://github.com/openai/whisper">official implementation</a>. Nevertheless, the accuracy of this model is
nothing short of remarkable, even for the small version with "just"
39M parameters. It is truly astonishing to think that a few years ago,
having an Open Source Speech Recognition model as swift and accurate
as this one would have been deemed nearly implausible.
</p>

<p>
When I want to transcribe the new episodes from the last 3 days, I
just need to run this (I also have a <b>cron job</b> configured to run it):
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --transcribe-days 3
</pre>
</div>

<p>
For curious minds, you can check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/transcription.py">transcription.py</a> module.
</p>
</div>
</div>
<div id="outline-container-orgd17281d" class="outline-2">
<h2 id="orgd17281d">üìá index (episodes trancriptions)</h2>
<div class="outline-text-2" id="text-orgd17281d">
<p>
The process of generating episode transcripts involves breaking them
down into fragments, each comprising approximately 40 words. <b>Voilib</b>
employs the <a href="https://www.sbert.net/">sentence-transformers</a> <code>Python</code> library to calculate the
<b>embedding of each 40-words fragment</b>, effectively transforming it into
a <b>384-dimensional vector of floating point numbers</b>.
</p>

<p>
To shed light on the concept of <b>embeddings</b>, they can be defined as
lower-dimensional spaces that allow for the translation of
high-dimensional vectors.  The goal of embeddings is to capture
semantic similarity, ensuring that inputs with similar meanings are
placed closer together in the embedding space.
</p>

<p>
The <a href="https://www.sbert.net/">sentence-transformers</a> library stands out as the optimal choice for
creating text embeddings. This is the description from their <a href="https://www.sbert.net/">website</a>:
</p>

<blockquote>
<p>
You can use this framework to compute sentence / text embeddings for
more than 100 languages. These embeddings can then be compared
e.g. with cosine-similarity to find sentences with a similar
meaning. This can be useful for semantic textual similar, semantic
search, or paraphrase mining.
</p>

<p>
The framework is based on PyTorch and Transformers and offers a large
collection of pre-trained models tuned for various tasks. Further, it
is easy to fine-tune your own models.
</p>
</blockquote>

<p>
The model <b>Voilib</b> is using to calculate the embeddings is
<code>multi-qa-MiniLM-L6-cos-v1</code>. This model have been specifically trained
for Semantic Search with <a href="https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-dot-v1#training">215M question-answer pairs</a> from various
sources and domains.
</p>

<p>
You can find the code for Voilib's embedding calculation in the
<a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/embedding.py">embedding.py</a> module.
</p>

<p>
Those calculated vectors are then stored in a <b>vector database</b>, one of
the main components of the system. More on this in the next section.
</p>
</div>
</div>
<div id="outline-container-org2eeaecc" class="outline-2">
<h2 id="org2eeaecc">üîç query (embeddings)</h2>
<div class="outline-text-2" id="text-org2eeaecc">
<p>
Each episode's embeddings are meticulously preserved within a <b>vector
database</b>. In recent months, we have witnessed a surge in new
technologies specifically designed for storing embeddings. These
innovative solutions empower us to efficiently store embeddings and
seamlessly query them using cutting-edge <b>Approximate Nearest Neighbor
search</b> algorithms.
</p>

<p>
During the initial stages, <b>Voilib</b> relied on <a href="https://github.com/facebookresearch/faiss">Meta's FAISS</a> library for
embedding storage. However, to enhance the system and include
additional metadata for each embedding (that can be also used to
filter queries), I decided to migrate to <a href="https://qdrant.tech/">qdrant</a>, a higher-level
solution. With <a href="https://qdrant.tech/">qdrant</a>, we achieve the ability to incorporate
supplementary metadata while seamlessly managing embeddings. As part
of this evolution, <b>Voilib</b> now operates its own instance of the <a href="https://hub.docker.com/r/qdrant/qdrant/">qdrant
server</a>, further ensuring data autonomy and control.
</p>

<p>
For every <b>user prompt</b>, Voilib performs a swift calculation of the
corresponding embedding and efficiently queries the vector
database. This process enables the system to swiftly identify and
return the most relevant results, ensuring a seamless and satisfying
user experience.
</p>

<p>
Of course, there is another command to calculate and store embeddings
from all pending episodes:
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --store
</pre>
</div>

<p>
More, in the <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/vector.py">vector.py</a> module.
</p>
</div>
</div>
<div id="outline-container-orgf6f4f71" class="outline-2">
<h2 id="orgf6f4f71">happy to receive your feedback</h2>
<div class="outline-text-2" id="text-orgf6f4f71">
<p>
Please feel free to reach out to me at <code>unmonoqueteclea@gmail.com</code> with
your thoughts, suggestions, or any inquiries.
</p>

<p>
I am eager to know which podcasts you would like to see available on
<a href="https://voilib.com/">Voilib</a>. Additionally, if there are any specific features that you
believe would enhance your user experience and make your life easier,
please do not hesitate to share them with me. It's a fantastic
opportunity to contribute to the open-source community.
</p>

<p>
If you have been considering hosting your own instance, I would be
thrilled to support and guide you through the process.
</p>

<p>
I look forward to hearing from you!
</p>
</div>
</div>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html</link>
  <guid>https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html</guid>
  <pubDate>Thu, 03 Aug 2023 20:26:00 +0200</pubDate>
</item>
<item>
  <title><![CDATA[voilib is now open source]]></title>
  <description><![CDATA[
<p>
Today, I decided to <b>open-source</b> <a href="https://voilib.com">Voilib</a> üéâ, the podcast search engine I
launched in December 2022. You can now <b>run your own instance</b> of it and
transcribe and index your favorite podcasts (or even your own
content!).You can find it on <a href="https://github.com/unmonoqueteclea/voilib">Github</a> or <a href="https://gitlab.com/unmonoqueteclea/voilib">Gitlab</a>.
</p>

<p>
Appearing in <a href="https://news.ycombinator.com/item?id=34115618">Show
HN</a> was a big boost for the project. That post was the main source of
traffic during the first days of life of <a href="https://voilib.com">Voilib</a>. I am thrilled to see
that many of those initial users still use it today to discover
relevant podcast episodes on topics they are interested in. Throughout
these months, I have received valuable feedback and kind words from
some of them.
</p>


<figure id="org94f3aaa">
<img src="https://unmonoqueteclea.github.io/static/feedback-voilib.png" alt="feedback-voilib.png" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>Feedback from a Voilib user</figcaption>
</figure>

<p>
Since I am not offering <code>Voilib PRO</code> any more (I may talk about this in
the future) the only funding for this project, to at least cover
server expenses, will come from <a href="https://ko-fi.com/unmonoqueteclea">donations</a> and <a href="https://ko-fi.com/unmonoqueteclea/commissions">customized assistance</a> to
people maintaining their own instances.
</p>

<p>
In the following weeks (well&#x2026; maybe months), I will publish some
blog posts explaining how the system works. I consider this is the
kind of content I would have loved to find some months ago when many
people suddenly became <code>prompt engineers</code>, but not so many people really
understood how to build actual LLM-based products beyond the chat
interface.
</p>

<p>
<b>UPDATE</b> <span class="timestamp-wrapper"><span class="timestamp">[2023-08-04 Fri] </span></span> Read <a href="https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html">here</a> about the technology behind <b>Voilib</b>.
</p>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div>]]></description>
  <category><![CDATA[projects]]></category>
  <link>https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html</link>
  <guid>https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html</guid>
  <pubDate>Sun, 02 Jul 2023 12:32:00 +0200</pubDate>
</item>
</channel>
</rss>
