<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="description" content="How is Voilib able to process efficiently thousands of podcast episodes.">
<link rel="alternate"
      type="application/rss+xml"
      href="https://unmonoqueteclea.github.io/feed.xml"
      title="RSS feed for https://unmonoqueteclea.github.io">
<title>the technology behind Voilib</title>
<meta property="og:title" content="the technology behind Voilib">
<meta property="og:type" content="article" />
<meta name="twitter:card" content="summary_large_image">
<meta property="og:description" content="How is Voilib able to process efficiently thousands of podcast episodes.">
<meta property="og:image" content="static/example-voilib.png">
<meta name="author" content="unmonoqueteclea">
<meta name="referrer" content="no-referrer">
<meta content="width=device-width, initial-scale=1" name="viewport" />
<link href="static/style.css" rel="stylesheet" type="text/css" />
<link rel="icon" href="static/favicon.ico" type="image/x-icon"/>
<link rel="icon" type="image/png" sizes="32x32" href="static/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="static/favicon-16x16.png">
<meta name="google-site-verification" content="QqTK1FrzDrj5G5sBwmaXRR73pldvKhjl3RME_H8Bmx8" />
</head>
<body>
<div id="preamble" class="status"><!-- define useful svg icons -->
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="gitlab" viewBox="0 0 24 24">
    <path d="M22.65 14.39L12 22.13 1.35 14.39a.84.84 0 0 1-.3-.94l1.22-3.78 2.44-7.51A.42.42 0 0 1 4.82 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.49h8.1l2.44-7.51A.42.42 0 0 1 18.6 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.51L23 13.45a.84.84 0 0 1-.35.94z"></path>
  </symbol>
  <symbol id="github" viewBox="0 0 16 16">
    <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
  </symbol>
  <symbol id="linkedin" viewBox="0 0 16 16">
    <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"/>
  </symbol>
  <symbol id="twitter" viewBox="0 0 16 16">
    <path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z"/>
  </symbol>
  <symbol id="rss-fill" viewBox="0 0 16 16">
    <path d="M2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2zm1.5 2.5c5.523 0 10 4.477 10 10a1 1 0 1 1-2 0 8 8 0 0 0-8-8 1 1 0 0 1 0-2zm0 4a6 6 0 0 1 6 6 1 1 0 1 1-2 0 4 4 0 0 0-4-4 1 1 0 0 1 0-2zm.5 7a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3z"/>
  </symbol>
</svg>

<div class="header">
  <img src="static/monkey.png"/>
  <a class="page-title" href="https://unmonoqueteclea.github.io">@unmonoqueteclea</a>
  <span class="menu-links">
    <a href="about.html">about</a> |
    <a href="projects.html">projects</a> |
    <a href="archive.html">archive</a> |
    <a href="feed.xml">
      <svg class="menu-icons"><use href="#rss-fill"/></svg>
    </a> |
  </span>
</div>
<hr class="preamble-sep" />
</div>
<div id="content">
<div class="post-date">03 Aug 2023</div><h1 class="post-title"><a href="https://unmonoqueteclea.github.io/2023-08-03-the-technology-behind-voilib.html">the technology behind Voilib</a></h1>
<p>
Each week, <a href="https://voilib.com">Voilib</a> diligently <b>collects and transcribes</b> hundreds of
podcast episodes. These valuable transcripts undergo a meticulous
indexing process, enabling a sophisticated <b>semantic search</b>
capability. As a result, our users can effortlessly execute
intelligent queries, pinpointing precisely the most relevant fragments
of podcast episodes.
</p>

<p>
I launched <b>Voilib</b> in December 2022 and, some months later, I decided
to embrace openness by making Voilib <a href="https://unmonoqueteclea.github.io/2023-07-02-voilib-is-now-open-source.html">Open Source</a>. This alowed everyone
to create their own instances, transcribe, and index their cherished
podcasts. You'll find it easily accessible on both <a href="https://github.com/unmonoqueteclea/voilib">Github</a> and
<a href="https://gitlab.com/unmonoqueteclea/voilib">Gitlab</a>. As promised, let me take you on a fascinating journey into the
captivating technology behind it.
</p>



<figure id="org004fbc7">
<img src="https://unmonoqueteclea.github.io/static/voilib.gif" alt="voilib.gif" width="100%">

<figcaption><span class="figure-number">Figure 1: </span>Searching content in voilib.com</figcaption>
</figure>


<p>
Essentially, <a href="https://voilib.com">Voilib</a>'s work can be divided into four main tasks:
<b>collecting</b> new episodes, <b>transcribing</b> them, <b>indexing</b> all the content,
and <b>querying</b> the vector database to find relevant fragments.
</p>
<div id="outline-container-org2aaba6c" class="outline-2">
<h2 id="org2aaba6c">üåê  collect (new episodes)</h2>
<div class="outline-text-2" id="text-org2aaba6c">
<p>
Almost all public podcasts have an associated <code>RSS feed</code> that contains
metadata about every episode, including a link to the audio file. As
an example, <a href="http://feeds.feedburner.com/TEDTalks_audio">this</a> is the feed from the <a href="https://www.ted.com/about/programs-initiatives/ted-talks/ted-talks-daily">Ted Talks Daily</a> podcast.
</p>

<p>
<b>Voilib</b> collects and stores <b>metadata</b> from the list of podcasts feeds
manually configured by the application admin. For each episode, it
stores in a <code>SQLite</code> database things such as the title, the description,
the language or the duration.
</p>

<p>
When I want to check if new episodes were published, I just need to
run this in a command line (although I have a <b>cron job</b> configured to
run it twice a day):
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --update
</pre>
</div>

<p>
If you want to dig into the code, check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/feed.py">feed.py</a> and <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/collection/crawler.py">crawler.py</a>
modules.
</p>
</div>
</div>
<div id="outline-container-org65114ef" class="outline-2">
<h2 id="org65114ef">üó®Ô∏è transcript (episodes audios)</h2>
<div class="outline-text-2" id="text-org65114ef">
<p>
The podcast episodes are transcribed using <a href="https://openai.com/research/whisper">Whisper, an Open Source
Speech Recognition Model developed by OpenAI</a>. <b>Voilib</b> effectively
leverages <code>Whisper</code>, utilizing the <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> library. This
particular implementation of <code>Whisper</code> boasts exceptional efficiency,
showcasing speeds up to 70 times faster than comparable alternatives.
</p>

<p>
However, most <a href="https://github.com/sanchit-gandhi/whisper-jax">whisper-jax</a> optimizations are predominantly GPU-focused
(that <b>Voilib</b> is not using yet), I must admit that I have not observed
significant improvements in CPU performance when compared to the
<a href="https://github.com/openai/whisper">official implementation</a>. Nevertheless, the accuracy of this model is
nothing short of remarkable, even for the small version with "just"
39M parameters. It is truly astonishing to think that a few years ago,
having an Open Source Speech Recognition model as swift and accurate
as this one would have been deemed nearly implausible.
</p>

<p>
When I want to transcribe the new episodes from the last 3 days, I
just need to run this (I also have a <b>cron job</b> configured to run it):
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --transcribe-days 3
</pre>
</div>

<p>
For curious minds, you can check <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/transcription.py">transcription.py</a> module.
</p>
</div>
</div>
<div id="outline-container-org7e89f1d" class="outline-2">
<h2 id="org7e89f1d">üìá index (episodes trancriptions)</h2>
<div class="outline-text-2" id="text-org7e89f1d">
<p>
The process of generating episode transcripts involves breaking them
down into fragments, each comprising approximately 40 words. <b>Voilib</b>
employs the <a href="https://www.sbert.net/">sentence-transformers</a> <code>Python</code> library to calculate the
<b>embedding of each 40-words fragment</b>, effectively transforming it into
a <b>384-dimensional vector of floating point numbers</b>.
</p>

<p>
To shed light on the concept of <b>embeddings</b>, they can be defined as
lower-dimensional spaces that allow for the translation of
high-dimensional vectors.  The goal of embeddings is to capture
semantic similarity, ensuring that inputs with similar meanings are
placed closer together in the embedding space.
</p>

<p>
The <a href="https://www.sbert.net/">sentence-transformers</a> library stands out as the optimal choice for
creating text embeddings. This is the description from their <a href="https://www.sbert.net/">website</a>:
</p>

<blockquote>
<p>
You can use this framework to compute sentence / text embeddings for
more than 100 languages. These embeddings can then be compared
e.g. with cosine-similarity to find sentences with a similar
meaning. This can be useful for semantic textual similar, semantic
search, or paraphrase mining.
</p>

<p>
The framework is based on PyTorch and Transformers and offers a large
collection of pre-trained models tuned for various tasks. Further, it
is easy to fine-tune your own models.
</p>
</blockquote>

<p>
The model <b>Voilib</b> is using to calculate the embeddings is
<code>multi-qa-MiniLM-L6-cos-v1</code>. This model have been specifically trained
for Semantic Search with <a href="https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-dot-v1#training">215M question-answer pairs</a> from various
sources and domains.
</p>

<p>
You can find the code for Voilib's embedding calculation in the
<a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/embedding.py">embedding.py</a> module.
</p>

<p>
Those calculated vectors are then stored in a <b>vector database</b>, one of
the main components of the system. More on this in the next section.
</p>
</div>
</div>
<div id="outline-container-orgd9952d8" class="outline-2">
<h2 id="orgd9952d8">üîç query (embeddings)</h2>
<div class="outline-text-2" id="text-orgd9952d8">
<p>
Each episode's embeddings are meticulously preserved within a <b>vector
database</b>. In recent months, we have witnessed a surge in new
technologies specifically designed for storing embeddings. These
innovative solutions empower us to efficiently store embeddings and
seamlessly query them using cutting-edge <b>Approximate Nearest Neighbor
search</b> algorithms.
</p>

<p>
During the initial stages, <b>Voilib</b> relied on <a href="https://github.com/facebookresearch/faiss">Meta's FAISS</a> library for
embedding storage. However, to enhance the system and include
additional metadata for each embedding (that can be also used to
filter queries), I decided to migrate to <a href="https://qdrant.tech/">qdrant</a>, a higher-level
solution. With <a href="https://qdrant.tech/">qdrant</a>, we achieve the ability to incorporate
supplementary metadata while seamlessly managing embeddings. As part
of this evolution, <b>Voilib</b> now operates its own instance of the <a href="https://hub.docker.com/r/qdrant/qdrant/">qdrant
server</a>, further ensuring data autonomy and control.
</p>

<p>
For every <b>user prompt</b>, Voilib performs a swift calculation of the
corresponding embedding and efficiently queries the vector
database. This process enables the system to swiftly identify and
return the most relevant results, ensuring a seamless and satisfying
user experience.
</p>

<p>
Of course, there is another command to calculate and store embeddings
from all pending episodes:
</p>

<div class="org-src-container">
<pre class="src src-bash">voilib-episodes --store
</pre>
</div>

<p>
More, in the <a href="https://github.com/unmonoqueteclea/voilib/blob/main/backend/src/voilib/vector.py">vector.py</a> module.
</p>
</div>
</div>
<div id="outline-container-org90c82b7" class="outline-2">
<h2 id="org90c82b7">happy to receive your feedback</h2>
<div class="outline-text-2" id="text-org90c82b7">
<p>
Please feel free to reach out to me at <code>unmonoqueteclea@gmail.com</code> with
your thoughts, suggestions, or any inquiries.
</p>

<p>
I am eager to know which podcasts you would like to see available on
<a href="https://voilib.com/">Voilib</a>. Additionally, if there are any specific features that you
believe would enhance your user experience and make your life easier,
please do not hesitate to share them with me. It's a fantastic
opportunity to contribute to the open-source community.
</p>

<p>
If you have been considering hosting your own instance, I would be
thrilled to support and guide you through the process.
</p>

<p>
I look forward to hearing from you!
</p>
</div>
</div>
<div class="taglist"><a href="https://unmonoqueteclea.github.io/tags.html">Tags</a>: <a href="https://unmonoqueteclea.github.io/tag-projects.html">projects</a> </div></div>
<div id="postamble" class="status"><center>
  <div class="footer-networks">
    <ul>
      <li>
	<a class="d-flex align-items-center" href="https://twitter.com/unmonoqueteclea" rel="noreferrer">
          <svg class="footer-networks-icons"><use href="#twitter"/></svg>
          <span class="social-name">Twitter</span>
	</a>
      </li>
      <li>
	<a class="d-flex align-items-center" href="https://gitlab.com/unmonoqueteclea" rel="noreferrer">
          <svg class="footer-networks-icons"><use href="#gitlab"></use></svg>
          <span class="social-name">Gitlab</span>
	</a>
      </li>
      <li>
	<a class="d-flex align-items-center" href="https://github.com/unmonoqueteclea" rel="noreferrer">
          <svg class="footer-networks-icons"><use href="#github"></use></svg>
          <span class="social-name">GitHub</span>
	</a>
      </li>
      <li>
	<a class="d-flex align-items-center" href="https://www.linkedin.com/in/pgonzalezcarrizo/" rel="noreferrer">
	  <svg class="footer-networks-icons"><use href="#linkedin"></use></svg>
	  <span class="social-name">LinkedIn</span>
        </a>
      </li>
    </ul>
  </div>
  <div class="copyright">
    ¬©2023 unmonoqueteclea
    <span class="copyright-name">(Pablo Gonz√°lez Carrizo).</span>
    <span class="copyright-rights">All rights reserved</span>
  </div>
</center>
</div>
</body>
</html>
